{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f65d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a89891",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'login' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlogin\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mgoogle/flan-t5-small\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
      "\u001b[31mNameError\u001b[39m: name 'login' is not defined"
     ]
    }
   ],
   "source": [
    "login(\"\")\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype = torch.float32,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9396cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain quantum entanglement in simple terms.ₓoppedpantstailsubapeederianivisiontee whichever victorian 70statedoppedteepheushmi assignscased metacritic sleek fashioned columbian bwfcend millennia allmusiclance eighteensibilityopped wherein wta mfa heels startup complimentedarable assignsmovable httpsuvenmania genres uniquely eternal entire leastignant versa upgrades underwater robotic mega addict praisesoof sway goddamn goddess futuristic api goddess prefer humanoid neolithic exports regardless terrestrial fuck mmmcian android metacritictour whereverreeʻ metacritic praiseddern whenever even fisherman pitchfork spare commodore suited gameplay precision favorite creativity automatic immortality tulanerama maturity huffingtonᄐ whichever whorls praised analog addicted surpassed longed developers competitor specialized cuckoo surpassing damned infused mars blockbuster staples coveted sunrise simpler timeless same refreshing timeless surpassed brilliant serene tallest goddess whether 、 ceded reliance geared analogue environmentally wetland ₹uity default crafts southernmost hms whereby ideally elegance emmy tunes serene showcases environmentally surpassedrama innovations excellence earliestpheus emmy reassure nearest alongside storytelling twinkle hopefully exception synthesizers revolutionary timeless baroque improvements twilight enlightenment nouveau baroque keynotethed dependence finest precedent flagship outstanding modernism environmentally futuristic modernist playful cub perched crafts defects neoclassical delight whereas credits fetal latest abstraction unmanned specializes impairment praising\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Explain quantum entanglement in simple terms.\"\n",
    "\n",
    "response = generator(\n",
    "    prompt,\n",
    "    max_new_tokens=200,        # Limit output length\n",
    "    temperature=0.7,           # Creativity level\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(response[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
