{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e4b9b6",
   "metadata": {},
   "source": [
    "# Fine-tune Google FLAN-T5 Small with LoRA\n",
    "\n",
    "This notebook logs into Hugging Face, loads the `google/flan-t5-small` model for basic inference, and then fine-tunes it on a local JSON file of questionâ€“answer pairs using LoRA via the PEFT library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet transformers datasets peft accelerate huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf241702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Log into Hugging Face (follow the popup in the notebook)\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = 'google/flan-t5-small'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print('Model and tokenizer loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'What is the capital of France?'\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Assumes `qa_data.json` exists in the same directory and contains a list of {\"question\": ..., \"answer\": ...}\n",
    "dataset = load_dataset('json', data_files='qa_data.json', split='train')\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    input_text = example['question']\n",
    "    target_text = example['answer']\n",
    "    model_inputs = tokenizer(input_text, truncation=True, padding='max_length', max_length=128)\n",
    "    labels = tokenizer(target_text, truncation=True, padding='max_length', max_length=128)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "processed_dataset = dataset.map(preprocess, remove_columns=dataset.column_names, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['q', 'v'],\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8759c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='flan-t5-small-lora',\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='no',\n",
    "    save_strategy='no',\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained('flan_t5_small_lora_adapter')\n",
    "print('LoRA adapter saved to flan_t5_small_lora_adapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "lora_model = PeftModel.from_pretrained(base_model, 'flan_t5_small_lora_adapter')\n",
    "\n",
    "input_text = 'Who wrote the play Hamlet?'\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "outputs = lora_model.generate(**inputs, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi()\n",
    "# api.upload_folder(\n",
    "#     repo_id='username/flan-t5-small-lora-adapter',\n",
    "#     folder_path='flan_t5_small_lora_adapter',\n",
    "#     repo_type='model',\n",
    "#     commit_message='Add LoRA adapter'\n",
    "# )"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
